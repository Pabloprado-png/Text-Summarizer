{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nltk #Processamento e ordenação de tokens\n",
    "import heapq #Ordenação de arrays\n",
    "import re # Interpretador de expressões regulares\n",
    "import bs4 as bs # Bibliteca utilizada para lidar com os arquivos XML vindos do SOUP que iremos extrair da Wikipedia\n",
    "import urllib.request # Realizar requests no python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extração de dados da web, utilizamos Wikipedia pela pratica em sala\n",
    "source = urllib.request.urlopen(\"https://en.wikipedia.org/wiki/Xenomorph_(band)\").read()\n",
    "print (source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extração de arquivos de XML para o formato de texto\n",
    "soup = bs.BeautifulSoup(source,'lxml')\n",
    "text = \"\"\n",
    "for paragraph in soup.find_all('p'):\n",
    "    text += paragraph.text\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Removeremos caracteres indesejados vindos da Wikipedia como numerações, etc. e os lematizamos\n",
    "text = re.sub(r'[[0-9]*]',' ', text)\n",
    "text = re.sub(r's+',' ', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clean_text = text.lower()\n",
    "clean_text = re.sub(r'W', ' ', clean_text)\n",
    "clean_text = re.sub(r'd', ' ', clean_text)\n",
    "clean_text = re.sub(r's+', ' ', clean_text)\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizada a tokenização para a manipulação de dados\n",
    "sentences = nltk.sent_tokenize(clean_text)\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usar os dados pré processados para contarmos a frequencia das palavras\n",
    "word2count = {}\n",
    "for word in nltk.word_tokenize(clean_text):\n",
    "    if word not in stop_words:\n",
    "      if word not in word2count.keys():\n",
    "         word2count[word] = 1\n",
    "      else:\n",
    "         word2count[word] += 1 #conta a frequência das palavras\n",
    "         for key in word2count.keys():\n",
    "            word2count[key] = word2count[key] /max(word2count.values()) #transforma em porcentagem\n",
    "print(word2count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#De acordo com a frequencia as palavras serão pontuadas\n",
    "sent2score = {}\n",
    "\n",
    "for sentence in sentences:\n",
    "    for word in nltk.word_tokenize(sentence.lower()):\n",
    "        if word in word2count.keys():\n",
    "            if len(sentence.split(' ')) < 30:\n",
    "                if sentence not in sent2score.keys():\n",
    "                    sent2score[sentence] = word2count[word]\n",
    "                else:\n",
    "                    sent2score[sentence] += word2count[word]\n",
    "print(sent2score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As sentenças de palavras com pontuações mais altas serão utilizadas para ordenação\n",
    "best_sentences = heapq.nlargest(10, sent2score,key=sent2score.get)\n",
    "\n",
    "print(\"-------------------------------------------------------------\")\n",
    "for sentence in best_sentences:\n",
    "    print(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba4535523d4b597ce825aece98349bc95b5cfa8e4c0a2d0602965e09017439b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
